{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- Pytest vs Unittest: Why Some prefer Pytest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Less boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "class TestAddOne(unittest.TestCase):\n",
    "    def test_add_one(self):\n",
    "        self.assertEqual(add_one(3), 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "def test_add_one():\n",
    "    assert func(3) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assert works everywhere vs assertEqual, assertTrue, etc...\n",
    "- fewer lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Much more helpful error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_add_one (test_unittests.example1.test_examples.TestAddOne)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junior/Repos/Pytest-Tutorial/test_unittests/example1/test_examples.py\", line 8, in test_add_one\n",
      "    self.assertEqual(add_one(3), 5)\n",
      "AssertionError: 4 != 5\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest test_unittests/example1/test_examples.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example1/test_examples.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________________ test_add_one _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_add_one\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m add_one(\u001b[94m3\u001b[39;49;00m) == \u001b[94m5\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 4 == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 4 = add_one(3)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_pytests/example1/test_examples.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m_____________________________ test_dicts_equality ______________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_dicts_equality\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m {\u001b[33m'\u001b[39;49;00m\u001b[33ma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[94m2\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m3\u001b[39;49;00m} == {\u001b[33m'\u001b[39;49;00m\u001b[33ma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[94m2\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m3\u001b[39;49;00m}\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert {'a': 1, 'b': 2, 'c': 3} == {'a': 0, 'c': 3, 'd': 2}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Omitting 1 identical items, use -vv to show\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Differing items:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'a': 1} != {'a': 0}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Left contains 1 more item:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'b': 2}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Right contains 1 more item:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'d': 2}...\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         ...Full output truncated (2 lines hidden), use '-vv' to show\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_pytests/example1/test_examples.py\u001b[0m:8: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_pytests/example1/test_examples.py::test_add_one - assert 4 == 5\n",
      "FAILED test_pytests/example1/test_examples.py::test_dicts_equality - Assertio...\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m2 failed\u001b[0m\u001b[31m in 0.12s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- error messages much more detailed and helpful\n",
    "- error messages are tailored to the type of objects tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Parameterized test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "class TestAddOne(unittest.TestCase):\n",
    "    def test_add_one__to_one(self):\n",
    "        self.assertEqual(add_one(1), 2)\n",
    "    \n",
    "    def test_add_one__to_two(self):\n",
    "        self.assertEqual(add_one(2), 3)\n",
    "        \n",
    "    def test_add_one__to_five(self):\n",
    "        self.assertEqual(add_one(5), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest test_unittests/example2/test_examples.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "@pytest.mark.parametrize('num, expected',[(1, 2), (2, 3), (5, 6)])\n",
    "def test_add_one(num, expected):\n",
    "    assert add_one(num) == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example2/test_examples.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Less lines of codes to maintain\n",
    "- Much more readable\n",
    "- Very easy to add new cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Tagging test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.mark.slow\n",
    "@pytest.mark.integration\n",
    "def test_http_call():\n",
    "    pass\n",
    "    \n",
    "    \n",
    "@pytest.mark.slow\n",
    "def test_http_call2():\n",
    "    pass\n",
    "    \n",
    "    \n",
    "@pytest.mark.fast\n",
    "@pytest.mark.unit\n",
    "def test_add():\n",
    "    pass\n",
    "    \n",
    "@pytest.mark.unit\n",
    "def test_add2():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 4 items / 3 deselected / 1 selected                                  \u001b[0m\n",
      "\n",
      "test_pytests/example3/test_examples.py \u001b[32m.\u001b[0m\u001b[33m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_pytests/example3/test_examples.py:3\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:3: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:4\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.integration\n",
      "\n",
      "test_pytests/example3/test_examples.py:9\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:14\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.fast - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.fast\n",
      "\n",
      "test_pytests/example3/test_examples.py:15\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:15: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "test_pytests/example3/test_examples.py:19\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:19: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m3 deselected\u001b[0m, \u001b[33m\u001b[1m6 warnings\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example3/  -m fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 4 items / 2 deselected / 2 selected                                  \u001b[0m\n",
      "\n",
      "test_pytests/example3/test_examples.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_pytests/example3/test_examples.py:3\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:3: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:4\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.integration\n",
      "\n",
      "test_pytests/example3/test_examples.py:9\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:14\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.fast - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.fast\n",
      "\n",
      "test_pytests/example3/test_examples.py:15\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:15: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "test_pytests/example3/test_examples.py:19\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:19: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m================= \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m2 deselected\u001b[0m, \u001b[33m\u001b[1m6 warnings\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example3/ -m unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 4 items / 3 deselected / 1 selected                                  \u001b[0m\n",
      "\n",
      "test_pytests/example3/test_examples.py \u001b[32m.\u001b[0m\u001b[33m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_pytests/example3/test_examples.py:3\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:3: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:4\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.integration\n",
      "\n",
      "test_pytests/example3/test_examples.py:9\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:14\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.fast - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.fast\n",
      "\n",
      "test_pytests/example3/test_examples.py:15\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:15: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "test_pytests/example3/test_examples.py:19\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:19: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m3 deselected\u001b[0m, \u001b[33m\u001b[1m6 warnings\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example3/  -m integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 4 items / 2 deselected / 2 selected                                  \u001b[0m\n",
      "\n",
      "test_pytests/example3/test_examples.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_pytests/example3/test_examples.py:3\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:3: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:4\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.integration\n",
      "\n",
      "test_pytests/example3/test_examples.py:9\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "test_pytests/example3/test_examples.py:14\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.fast - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.fast\n",
      "\n",
      "test_pytests/example3/test_examples.py:15\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:15: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "test_pytests/example3/test_examples.py:19\n",
      "  /Users/junior/Repos/Pytest-Tutorial/test_pytests/example3/test_examples.py:19: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m================= \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m2 deselected\u001b[0m, \u001b[33m\u001b[1m6 warnings\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example3/  -m slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tagging enables to group tests in multiple different ways\n",
    "- Can help seperate unittests from integration tests and allow for instance running the later only if all of the former are successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Dependencies Injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest: Setup/TearDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import unittest\n",
    "\n",
    "class Transaction():\n",
    "    @staticmethod \n",
    "    def convert_to_pound(amount):\n",
    "         return 'NEW_AMOUNT GBP'\n",
    "    \n",
    "    @staticmethod \n",
    "    def debit(account, amount):\n",
    "        pass\n",
    "\n",
    "def get_db_conn():\n",
    "    time.sleep(2.5)\n",
    "    return 'db-conn'\n",
    "    \n",
    "\n",
    "class TestTransaction(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        print('Setting up the database connection')\n",
    "        self._conn = get_db_conn()\n",
    "        \n",
    "        print('Setting up the allowed currencies')\n",
    "        self._valid_currencies = set(['GBP', 'CFA', 'Dollar', 'Yen', 'Euro'])\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('Terminating the database connection \\n')\n",
    "        del self._conn\n",
    "        \n",
    "        \n",
    "    def test_debit(self):\n",
    "        print('\\t *** TESTING DEBIT ***')\n",
    "        account_id = 1\n",
    "        amount = '150 GBP'\n",
    "        # account = self._conn.get_account(account_id)\n",
    "        # balance = account.balance\n",
    "        \n",
    "        # Transaction.debit(account, amount)\n",
    "        \n",
    "        # self.assertEqual(balance - amount, account.balance)\n",
    "    \n",
    "    def test_convert_to_pound(self):\n",
    "        print('\\t *** TESTING CONVERT_TO_POUND ***')\n",
    "        amount = '150 Dollar'\n",
    "        _, currency = amount.split(' ')\n",
    "        self.assertTrue(currency in self._valid_currencies)\n",
    "\n",
    "        new_amount = Transaction.convert_to_pound(amount)\n",
    "        _, new_currency = new_amount.split(' ')\n",
    "        self.assertEqual(new_currency, 'GBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the database connection\n",
      "Setting up the allowed currencies\n",
      "\t *** TESTING CONVERT_TO_POUND ***\n",
      "Terminating the database connection \n",
      "\n",
      ".Setting up the database connection\n",
      "Setting up the allowed currencies\n",
      "\t *** TESTING DEBIT ***\n",
      "Terminating the database connection \n",
      "\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 10.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m unittest test_unittests/example4/test_examples.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pytest \n",
    "\n",
    "class Transaction():\n",
    "    @staticmethod \n",
    "    def convert_to_pound(amount):\n",
    "         return 'NEW_AMOUNT GBP'\n",
    "    \n",
    "    @staticmethod \n",
    "    def debit(account, amount):\n",
    "        pass\n",
    "\n",
    "def get_db_conn():\n",
    "    time.sleep(2.5)\n",
    "    return 'db-conn'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#### FIXTURES #### \n",
    "@pytest.fixture\n",
    "def valid_currencies():\n",
    "    print('Setting up the allowed currencies')\n",
    "    return set(['GBP', 'CFA', 'Dollar', 'Yen', 'Euro'])  \n",
    "    \n",
    "@pytest.fixture\n",
    "def conn():\n",
    "    print('Setting up the database connection')\n",
    "    _conn = get_db_conn()\n",
    "    \n",
    "    yield _conn\n",
    "    \n",
    "    print('Terminating the database connection \\n')\n",
    "    del _conn \n",
    "    \n",
    "\n",
    "#### TESTS ####      \n",
    "def test_debit(conn):\n",
    "    print('\\t *** TESTING DEBIT ***')\n",
    "    account_id = 1\n",
    "    amount = '150 GBP'\n",
    "    # account = conn.get_account(account_id)\n",
    "    # balance = account.balance\n",
    "\n",
    "    # Transaction.debit(account, amount)\n",
    "\n",
    "    # self.assertEqual(balance - amount, account.balance)\n",
    "\n",
    "def test_convert_to_pound(valid_currencies):\n",
    "    print('\\t *** TESTING CONVERT_TO_POUND ***')\n",
    "    amount = '150 Dollar'\n",
    "    _, currency = amount.split(' ')\n",
    "    assert currency in valid_currencies\n",
    "\n",
    "    new_amount = Transaction.convert_to_pound(amount)\n",
    "    _, new_currency = new_amount.split(' ')\n",
    "    assert new_currency == 'GBP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example4/test_examples.py Setting up the database connection\n",
      "\t *** TESTING DEBIT ***\n",
      "\u001b[32m.\u001b[0mTerminating the database connection \n",
      "\n",
      "Setting up the allowed currencies\n",
      "\t *** TESTING CONVERT_TO_POUND ***\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 2.51s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example4/ -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It’s obvious which tests are using a resource, as the resource is listed in the test param list.\n",
    "- I don’t have to artificially create classes (or move tests from one file to another) just to separate fixture usage.\n",
    "- The teardown code is tightly coupled with the setup code for one resource.\n",
    "- Scope for the lifetime of the resource is specified at the location of the resource setup code. This ends up being a huge benefit when you want to fiddle with scope to save time on testing. If everything starts going complex, it’s a one line change to specify function scope, and have setup/teardown run around every function/method.\n",
    "- It’s less code. The pytest solution is smaller than the class solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/ Useful and user-friendly buit-in fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Pytest | tmpdir fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one(tmpdir):\n",
    "    (tmpdir / 'foo.txt').write('hello world!')\n",
    "    assert 1 == len(tmpdir.listdir())    \n",
    "\n",
    "def test_two(tmpdir):\n",
    "    assert 0 == len(tmpdir.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example5/test_examples.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example5/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Pytest | tmpdir fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def test_one(monkeypatch):\n",
    "    monkeypatch.setenv('FOO', 'BAR')\n",
    "    assert 'FOO' in os.environ\n",
    "    \n",
    "def test_two():\n",
    "    assert 'FOO' not in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example6/test_examples.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example6/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7/ Many more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plugins\n",
    "- pytest-django: write tests for django apps, using pytest integration.\n",
    "- pytest-twisted: write tests for twisted apps, starting a reactor and processing deferreds from test functions.\n",
    "- pytest-cov: coverage reporting, compatible with distributed testing\n",
    "- pytest-xdist: to distribute tests to CPUs and remote hosts, to run in boxed mode which allows to survive segmentation faults, to run in looponfailing mode, automatically re-running - - failing tests on file changes.\n",
    "- pytest-instafail: to report failures while the test run is happening.\n",
    "- pytest-bdd: to write tests using behaviour-driven testing.\n",
    "- pytest-timeout: to timeout tests based on function marks or global definitions.\n",
    "- pytest-pep8: a --pep8 option to enable PEP8 compliance checking.\n",
    "- pytest-flakes: check source code with pyflakes.\n",
    "- oejskit: a plugin to run javascript unittests in live browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running tests written for nose\n",
    "#### Profiling test execution duration\n",
    "#### Dropping a PDB (Python Debugger) at the start of a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Good vs Bad Unittesting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNOWN FIX INPUT produces a KNOWN FIX OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg: testing a square root function\n",
    "import math\n",
    "\n",
    "def my_square_root(x):\n",
    "    res = math.sqrt(x)\n",
    "    return res \n",
    "\n",
    "\n",
    "def bad_test():\n",
    "    number = 10\n",
    "    expected_sqrt = 3.16227766\n",
    "    assert my_square_root(number) == expected_sqrt\n",
    "    \n",
    "def good_test():\n",
    "    number = 9\n",
    "    expected_sqrt = 3\n",
    "    assert my_square_root(number) == expected_sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deterministic & independent of external factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def is_midday_past(datetime_object):\n",
    "    current_hour = datetime_object.hour\n",
    "    midday_hour = 12\n",
    "    return current_hour >= midday_hour\n",
    "\n",
    "def bad_test():\n",
    "    utc_datetime = datetime.datetime.utcnow()\n",
    "    assert is_midday_past(utc_datetime) \n",
    "    \n",
    "def good_test():\n",
    "    today_1pm = datetime.datetime(2020, 4, 29, 13, 0, 0)\n",
    "    assert is_midday_past(today_1pm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Avoiding mutable global state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BAD\n",
    "\n",
    "students_database = ['John', 'Emma', 'Dilane', 'James', 'Alice']\n",
    "\n",
    "def add_student(name):\n",
    "    students_database.append(name)\n",
    "    \n",
    "def remove_student():\n",
    "    students_database.pop()\n",
    "    \n",
    "    \n",
    "students_count = len(students_database)\n",
    "\n",
    "def test_add_student():\n",
    "    new_student = 'Junior'\n",
    "    add_student(new_student)\n",
    "    \n",
    "    assert len(students_database) == students_count + 1\n",
    "    \n",
    "def test_remove_student():\n",
    "    remove_student()\n",
    "    \n",
    "    assert len(students_database) == students_count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Always avoid test interdependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Try keeping test-case/assertion ratio near to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Avoid using side-effecting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test should not depend on excessive setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Tests should not swallow exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Unlike code functions, it's ok to have very long names for test-cases functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The execution order of test-cases should not impact the result of any test-case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Use Mocks only when appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III- Monkey Patching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.1 Problems Patching Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mocks helps eliminates dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    y = bar(x) # DEPENDENCY HERE -> returns y which impacts the rest of our function\n",
    "    \n",
    "    if y > 10:\n",
    "        return x+y\n",
    "    return x-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tests methods that have no return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    if x > 10:\n",
    "        bar(x) # How do we know that bar(x) has been called?\n",
    "    else:\n",
    "        something_else(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulate error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(filename):\n",
    "    try:\n",
    "        return parse_large_file(filename)\n",
    "    except MemoryError: # How do we test this branch of the code without actually causing a real memory error\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.2 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example.py\n",
    "\n",
    "def db_persist(data):\n",
    "    raise NotImplemented\n",
    "\n",
    "def get_and_upper_and_persist():\n",
    "    data = input()\n",
    "    \n",
    "    if isinstance(data, str):\n",
    "        data = data.upper()\n",
    "        db_persist(data)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_example.py \n",
    "\n",
    "from example import get_and_upper_and_persist\n",
    "import pytest \n",
    "\n",
    "\n",
    "def test_get_and_upper_and_persist(monkeypatch):\n",
    "    monkeypatch.setattr('builtins.input', lambda:'string-data')\n",
    "    monkeypatch.setattr('example.db_persist', lambda x:None)\n",
    "    \n",
    "    data = get_and_upper_and_persist()\n",
    "    \n",
    "    assert data == 'STRING-DATA'\n",
    "    \n",
    "\n",
    "    \n",
    "def test_get_non_string_and_error(monkeypatch):\n",
    "    monkeypatch.setattr('builtins.input', lambda: 1)\n",
    "    \n",
    "    with pytest.raises(ValueError):\n",
    "        data = get_and_upper_and_persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.0, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/junior/Repos/Pytest-Tutorial\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_pytests/example7/test_example.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_pytests/example7/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
